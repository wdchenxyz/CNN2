{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import tensorflow as tf \n",
    "import tensorflow.keras as keras\n",
    "tf.config.gpu.set_per_process_memory_growth(True)\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils_modelnet as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset/modelnet2d/'\n",
    "class_set =  ['chair', 'car', 'lamp', 'airplane', 'person']\n",
    "\n",
    "dataset = ds.get_data_from_file(class_set, dataset_path)\n",
    "train_dataset, valid_dataset, test_dataset = ds.train_test_split(dataset)\n",
    "\n",
    "train_data, train_label = ds.split_data_label(train_dataset)\n",
    "test_data, test_label = ds.split_data_label(test_dataset)\n",
    "valid_data, valid_label = ds.split_data_label(valid_dataset)\n",
    "## train and validation\n",
    "print(\"Train Dataset: {}\".format(len(train_dataset)))\n",
    "print(\"Test Dataset: {}\".format(len(test_dataset)))\n",
    "print(\"Valid Dataset: {}\".format(len(valid_dataset)))\n",
    "num_classes = len(class_set)\n",
    "print(\"Number of Classes: {}\".format(num_classes))\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 48\n",
    "NUM_CHANNEL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binocular_dataset(data, label, batch_size=BATCH_SIZE):\n",
    "    def preprocess_image(left_image, right_image):\n",
    "        left_image = tf.image.decode_jpeg(left_image, channels=NUM_CHANNEL)\n",
    "        left_image = tf.image.resize(left_image, [IMG_SIZE, IMG_SIZE])\n",
    "        left_image /= 255.0\n",
    "\n",
    "        right_image = tf.image.decode_jpeg(right_image, channels=NUM_CHANNEL)\n",
    "        right_image = tf.image.resize(right_image, [IMG_SIZE, IMG_SIZE])\n",
    "        right_image /= 255.0  # normalize to [0,1] range\n",
    "        return left_image, right_image\n",
    "\n",
    "    def load_and_preprocess_image(left, right):\n",
    "        left_image = tf.io.read_file(left)\n",
    "        right_image = tf.io.read_file(right)\n",
    "        return preprocess_image(left_image, right_image)\n",
    "\n",
    "    # The tuples are unpacked into the positional arguments of the mapped function \n",
    "    def load_and_preprocess_from_path_label(data_path, label):\n",
    "        return load_and_preprocess_image(data_path[0], data_path[1]), label\n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices((data, label))\n",
    "    ds = ds.map(load_and_preprocess_from_path_label, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    ds = ds.shuffle(buffer_size=len(data))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    print(ds)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_binocular_dataset(train_data, train_label)\n",
    "test_ds = get_binocular_dataset(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility function\n",
    "def cmpooling(fmaps, scale_list, pool_stride):\n",
    "    # make sure the scale_list is in decending order\n",
    "    if scale_list[0] - scale_list[1] < 0:\n",
    "        scale_list = scale_list[::-1]\n",
    "        \n",
    "    # concentric multi-scale pooling\n",
    "    offset = [0] + [-(scale_list[i+1] - scale_list[0])//2 for i in range(len(scale_list) - 1)]\n",
    "    pool_maps = []\n",
    "    for offset, scale in zip(offset, scale_list):\n",
    "        slice_maps = tf.slice(fmaps, [0, offset, offset, 0], [-1, fmaps.shape[1]-offset*2, fmaps.shape[2]-offset*2, -1])\n",
    "        pool_map = tf.nn.max_pool2d(slice_maps, scale, pool_stride, \"VALID\")\n",
    "        pool_maps.append(pool_map)\n",
    "    \n",
    "    # assert same shape for all pool_map\n",
    "    for i in range(len(pool_maps)-1):\n",
    "        assert pool_maps[i].shape[1:] == pool_maps[-1].shape[1:]\n",
    "    return pool_maps\n",
    "\n",
    "# Concat the feature maps in different scale and convolution once. (paper version)\n",
    "class Monocular(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, ksize, **kwargs):\n",
    "        super(Monocular, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.ksize = ksize\n",
    "#         self.conv = tf.keras.layers.Conv2D(filters, ksize, input_shape=kwargs['input_shape'], activation='relu', padding='same')\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.conv = tf.keras.layers.Conv2D(self.filters, self.ksize, input_shape=input_shape, activation='relu', padding='same')\n",
    "    \n",
    "    def call(self, fmaps, scale_list, pool_stride):\n",
    "        pool_maps = cmpooling(fmaps, scale_list, pool_stride)\n",
    "        pool_maps = tf.concat(pool_maps, axis=-1)\n",
    "        return self.conv(pool_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_LIST = [1,3,5]\n",
    "def CNN2(input_shape, num_classes, scale_list):\n",
    "    left_eye = tf.keras.Input(input_shape, name='left_eye')\n",
    "    right_eye = tf.keras.Input(input_shape, name='right_eye')\n",
    "    \n",
    "    # parallax augmentation\n",
    "    parallax = left_eye - right_eye \n",
    "    left = tf.concat([left_eye, -parallax], axis=-1)\n",
    "    right = tf.concat([right_eye, parallax], axis=-1)\n",
    "    # \n",
    "    left1 = Monocular(6, 5, input_shape=input_shape, name='mono1_left')(left, scale_list=scale_list, pool_stride=2)\n",
    "    right1 = Monocular(6, 5, input_shape=input_shape, name='mono1_right')(right, scale_list=scale_list, pool_stride=2)\n",
    "    \n",
    "    left2 = Monocular(12, 5, name='mono2_left')(tf.concat([left1, right1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
    "    right2 = Monocular(12, 5, name='mono2_right')(tf.concat([right1, left1], axis=-1), scale_list=scale_list, pool_stride=1)\n",
    "    \n",
    "    left3 = Monocular(32, 3, name='mono3_left')(tf.concat([left2, right2], axis=-1), scale_list=scale_list, pool_stride=1)\n",
    "    right3 = Monocular(32, 3, name='mono3_right')(tf.concat([right2, left2], axis=-1), scale_list=scale_list, pool_stride=1)\n",
    "    \n",
    "    x = tf.concat([left3, right3], axis=-1)\n",
    "    x = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', name='conv1')(x)\n",
    "    x = tf.keras.layers.Conv2D(256, 1, strides=1, activation='relu', name='conv2')(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 1, strides=1, activation='relu', name='conv3')(x)\n",
    "    feature_vector = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    predicted_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(feature_vector)\n",
    "    \n",
    "    return tf.keras.Model([left_eye, right_eye], predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model, input_shape, num_classes, scale_list):\n",
    "    m = model(input_shape, num_classes, scale_list)\n",
    "    # learning rate schedule\n",
    "    initial_learning_rate = 0.0001\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=100000,\n",
    "                                                              decay_rate=0.96, staircase=True)\n",
    "    \n",
    "    # compile the model\n",
    "    m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),  # Optimizer\n",
    "                  # Loss function to minimize\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  # List of metrics to monitor\n",
    "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "                 )\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoints\n",
    "checkpoint_path = 'checkpoints/cnn2_modelnet/cp.ckpt'\n",
    "cnn2 = create_model(CNN2, input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNEL), num_classes=5, scale_list=SCALE_LIST)\n",
    "cnn2.load_weights(checkpoint_path)\n",
    "# Restore the weights\n",
    "loss, acc = cnn2.evaluate(test_ds)\n",
    "print(f\"Loss: {loss}, Acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
